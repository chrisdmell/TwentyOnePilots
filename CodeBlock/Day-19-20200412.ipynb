{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing logistic regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import math\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the amazon reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The shape of PRODUCTS dataset is (53072, 4)\n",
      "\n",
      " # of positive reviews 26579\n",
      "\n",
      " # of negative reviews 26493\n"
     ]
    }
   ],
   "source": [
    "products = pd.read_csv(\"amazon_baby_subset.csv\")\n",
    "\n",
    "display(products.head(1))\n",
    "\n",
    "print(\"\\n The shape of PRODUCTS dataset is {}\".format(products.shape))\n",
    "\n",
    "print(\"\\n # of positive reviews {}\".format(len(products[products[\"sentiment\"] == 1  ])))\n",
    "print(\"\\n # of negative reviews {}\".format(len(products[products[\"sentiment\"] == -1 ])))\n",
    "\n",
    "## This is not a class-imbalanced problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The lenght of important_words 193 \n",
      "\n",
      " Head of important words ['baby', 'one', 'great', 'love', 'use']\n"
     ]
    }
   ],
   "source": [
    "file_name_important_words = \"important_words.json\"\n",
    "\n",
    "with open (file_name_important_words, \"r\") as data:\n",
    "    important_words = json.load(data)\n",
    "    \n",
    "print(\"\\n The lenght of important_words {} \\n\\n Head of important words {}\".format(len(important_words), important_words[0:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  All of my kids have cried nonstop when I tried...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## get cleaned reviews \n",
    "\n",
    "products[\"review_clean\"] = products[\"review\"].str.replace(\"[{}]\".format(string.punctuation), \"\")\n",
    "\n",
    "display(products.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_comprehension = [1,2,3,4]\n",
    "\n",
    "a = [x**2 for x in list_comprehension]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference Between a Lambda Function and List Comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## takes couple of minutes\n",
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].astype('U').apply(lambda s : s.split().count(word))\n",
    "## astype(\"U\") makes it unicode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of data points that contains perfect are 2955\n"
     ]
    }
   ],
   "source": [
    "products[\"contains_perfect\"] = products[\"perfect\"] >= 1\n",
    "\n",
    "print(\"The # of data points that contains perfect are {}\".format(np.sum(products.contains_perfect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features_, label_):\n",
    "    \n",
    "    dataframe[\"intercept\"] = 1   ## the equation has an intercept, why is it kept to one?? \n",
    "    ## doesn't matter the co_ef starts with 0 so everything is zero\n",
    "    features_all =   [\"intercept\"] + features_  ## all features ## why is intercept added at first \n",
    "    return_df = dataframe[features_all].to_numpy() ## filter them all\n",
    "    dataframe_label = dataframe[label_].to_numpy() ## filter labels\n",
    "    \n",
    "    return return_df, dataframe_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature Matrix data \n",
      " [[1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " Sentiment data \n",
      " [1 1]\n"
     ]
    }
   ],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, \"sentiment\")\n",
    "\n",
    "print(\"\\n Feature Matrix data \\n {}\".format(feature_matrix[:2]))\n",
    "print(\"\\n Sentiment data \\n {}\".format(sentiment[:2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is from the line(linear or polynomial) and then the score is passed through a sigmoid to get probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenght of 1 instance of feature matrix :  194\n",
      "The lenght of important words  :  193\n"
     ]
    }
   ],
   "source": [
    "print(\"The lenght of 1 instance of feature matrix : \",len(feature_matrix[0]))\n",
    "print(\"The lenght of important words  : \", len(important_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of feature matrix : (53072, 194)\n",
      "\n",
      " Shape of Jth feature  : (194,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Shape of feature matrix : {}\".format(feature_matrix.shape))\n",
    "\n",
    "print(\"\\n Shape of Jth feature  : {}\".format(feature_matrix[7].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    '''\n",
    "    produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "    estimate ranges between 0 and 1.\n",
    "    '''\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    predinction = 1/(1+np.exp(-score))\n",
    "    return predinction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The derivate of log likelihood with respect to single co-efficent : that feature value * [labels - predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):  \n",
    "    '''\n",
    "    The derivatve wrt to each feature\n",
    "    The will give the value delta step to be added to the existing derivative\n",
    "    \n",
    "    feature * error\n",
    "    '''\n",
    "    derivative = np.dot(np.transpose(errors), feature) ## feature or indicator\n",
    "    return derivative\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    '''\n",
    "    We calcualte the likelikehood - \n",
    "    \n",
    "    score * ( indicator-1) - predictions\n",
    "    '''\n",
    "    indicator = (sentiment == +1) ## array with one row\n",
    "    \n",
    "    score = np.dot (feature_matrix, coefficients) ## on columns\n",
    "    \n",
    "    log_likelihood = np.log(1. + np.exp(-score)) ## one column\n",
    "    indicator_     = (np.transpose(np.array([indicator]))-1)*score\n",
    "    lp  = np.sum(indicator_ - log_likelihood)\n",
    "    \n",
    "    return lp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression Initial Conditions\n",
    "initial_coefficients = np.zeros((194,1))\n",
    "step_size = 1e-7\n",
    "max_iter = 301\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of scores (53072, 1)\n",
      "shape of left_side (53072, 1)\n",
      "\n",
      "indicator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of indicator (53072,)\n",
      "\n",
      "np array \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ..., False, False, False]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test_1 (1, 53072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test_2 (53072, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = np.dot (feature_matrix, coefficients)\n",
    "print(\"shape of scores {}\".format(score.shape))\n",
    "\n",
    "left_side = (np.transpose(np.array([indicator]))-1)*score\n",
    "print(\"shape of left_side {}\".format(left_side.shape))\n",
    "\n",
    "print(\"\\nindicator\")\n",
    "display(indicator[0:5])\n",
    "print(\"shape of indicator {}\".format(indicator.shape))\n",
    "\n",
    "print ('\\nnp array ')\n",
    "test_1 = np.array([indicator])\n",
    "display(test_1)\n",
    "display(test_1[:,4])\n",
    "print(\"shape of test_1 {}\".format(test_1.shape))\n",
    "\n",
    "\n",
    "test_2 = np.transpose(np.array([indicator]))\n",
    "#display(test_2)\n",
    "display(test_2[:7])\n",
    "print(\"shape of test_2 {}\".format(test_2.shape))\n",
    "\n",
    "## indicator True = +1 \n",
    "False-1\n",
    "\n",
    "display(sentiment [0:5])\n",
    "display(indicator [0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of coefs (194, 1)\n",
      "\n",
      "indicator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of is indicator (53072,) \n",
      "\n",
      "shape of is predictions(53072, 1) \n"
     ]
    }
   ],
   "source": [
    "coefficients = np.array(initial_coefficients)\n",
    "print(\"size of coefs {}\".format(coefficients.shape))\n",
    "predictions = predict_probability(feature_matrix, coefficients)\n",
    "\n",
    "indicator = (sentiment==+1)\n",
    "\n",
    "print(\"\\nindicator\")\n",
    "display(indicator[0:5])\n",
    "\n",
    "print(\"\\npredictions\")\n",
    "display(predictions[0:5])\n",
    "\n",
    "print(\"\\nshape of is indicator {} \". format( indicator.shape))\n",
    "print(\"\\nshape of is predictions{} \". format( predictions.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficients: D * 1\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    '''\n",
    "    input\n",
    "    feature_matrix = numpy array for feature matrix 194 columns\n",
    "    sentiment   - label for each review\n",
    "    initial_coef - all np.zero(len(coeff,1)\n",
    "    step_size  - heuristically \n",
    "    max_iter   - \n",
    "    '''\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    # lplist = []\n",
    "    for itr in range(max_iter):\n",
    "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
    "        # YOUR CODE HERE\n",
    "        # gives the scores\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "\n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "\n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = np.transpose(np.array([indicator])) - predictions\n",
    "\n",
    "        for j in range(len(coefficients)): # loop over each coefficient\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j]\n",
    "            # compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            # YOUR CODE HERE\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,j])\n",
    "\n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            # YOUR CODE HERE\n",
    "            \n",
    "            ## for each coeff the delta is added for hill climb\n",
    "            coefficients[j] += step_size*derivative\n",
    "\n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lplist = []\n",
    "            lplist.append(compute_log_likelihood(feature_matrix, sentiment, coefficients))\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            #print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "            #   (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    x= [i for i in range(len(lplist))]\n",
    "    plt.plot(x,lplist,'ro')\n",
    "    plt.show()\n",
    "    \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # predictions_positive 25126 \n"
     ]
    }
   ],
   "source": [
    "predictions_ = predict_probability(feature_matrix, coefficients)\n",
    "\n",
    "predictions_positive = (predictions_>0.5 ).sum()\n",
    "\n",
    "print(\"Total # predictions_positive {} \".format(predictions_positive) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53072,)\n",
      "(53072,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (np.transpose(predictions_.flatten()).shape)\n",
    "print ((products['sentiment']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51275866, 0.49265935, 0.50602867, 0.50196725, 0.53290719])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(predictions_[:5].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51275866, 0.49265935, 0.50602867, 0.50196725, 0.53290719])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_[:5].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_num: 39903, total_num: 53072\n",
      "0.7518653904130238\n"
     ]
    }
   ],
   "source": [
    "correct_num = np.sum((np.transpose(predictions_.flatten())> 0.5) == np.array(products['sentiment']>0))\n",
    "total_num = len(products['sentiment'])\n",
    "print (\"correct_num: {}, total_num: {}\".format(correct_num, total_num))\n",
    "accuracy = correct_num * 1./ total_num\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39903"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((np.transpose(predictions_.flatten() > 0.5)) == (products[\"sentiment\"]>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baby',\n",
       " 'one',\n",
       " 'great',\n",
       " 'love',\n",
       " 'use',\n",
       " 'would',\n",
       " 'like',\n",
       " 'easy',\n",
       " 'little',\n",
       " 'seat',\n",
       " 'old',\n",
       " 'well',\n",
       " 'get',\n",
       " 'also',\n",
       " 'really',\n",
       " 'son',\n",
       " 'time',\n",
       " 'bought',\n",
       " 'product',\n",
       " 'good',\n",
       " 'daughter',\n",
       " 'much',\n",
       " 'loves',\n",
       " 'stroller',\n",
       " 'put',\n",
       " 'months',\n",
       " 'car',\n",
       " 'still',\n",
       " 'back',\n",
       " 'used',\n",
       " 'recommend',\n",
       " 'first',\n",
       " 'even',\n",
       " 'perfect',\n",
       " 'nice',\n",
       " 'bag',\n",
       " 'two',\n",
       " 'using',\n",
       " 'got',\n",
       " 'fit',\n",
       " 'around',\n",
       " 'diaper',\n",
       " 'enough',\n",
       " 'month',\n",
       " 'price',\n",
       " 'go',\n",
       " 'could',\n",
       " 'soft',\n",
       " 'since',\n",
       " 'buy',\n",
       " 'room',\n",
       " 'works',\n",
       " 'made',\n",
       " 'child',\n",
       " 'keep',\n",
       " 'size',\n",
       " 'small',\n",
       " 'need',\n",
       " 'year',\n",
       " 'big',\n",
       " 'make',\n",
       " 'take',\n",
       " 'easily',\n",
       " 'think',\n",
       " 'crib',\n",
       " 'clean',\n",
       " 'way',\n",
       " 'quality',\n",
       " 'thing',\n",
       " 'better',\n",
       " 'without',\n",
       " 'set',\n",
       " 'new',\n",
       " 'every',\n",
       " 'cute',\n",
       " 'best',\n",
       " 'bottles',\n",
       " 'work',\n",
       " 'purchased',\n",
       " 'right',\n",
       " 'lot',\n",
       " 'side',\n",
       " 'happy',\n",
       " 'comfortable',\n",
       " 'toy',\n",
       " 'able',\n",
       " 'kids',\n",
       " 'bit',\n",
       " 'night',\n",
       " 'long',\n",
       " 'fits',\n",
       " 'see',\n",
       " 'us',\n",
       " 'another',\n",
       " 'play',\n",
       " 'day',\n",
       " 'money',\n",
       " 'monitor',\n",
       " 'tried',\n",
       " 'thought',\n",
       " 'never',\n",
       " 'item',\n",
       " 'hard',\n",
       " 'plastic',\n",
       " 'however',\n",
       " 'disappointed',\n",
       " 'reviews',\n",
       " 'something',\n",
       " 'going',\n",
       " 'pump',\n",
       " 'bottle',\n",
       " 'cup',\n",
       " 'waste',\n",
       " 'return',\n",
       " 'amazon',\n",
       " 'different',\n",
       " 'top',\n",
       " 'want',\n",
       " 'problem',\n",
       " 'know',\n",
       " 'water',\n",
       " 'try',\n",
       " 'received',\n",
       " 'sure',\n",
       " 'times',\n",
       " 'chair',\n",
       " 'find',\n",
       " 'hold',\n",
       " 'gate',\n",
       " 'open',\n",
       " 'bottom',\n",
       " 'away',\n",
       " 'actually',\n",
       " 'cheap',\n",
       " 'worked',\n",
       " 'getting',\n",
       " 'ordered',\n",
       " 'came',\n",
       " 'milk',\n",
       " 'bad',\n",
       " 'part',\n",
       " 'worth',\n",
       " 'found',\n",
       " 'cover',\n",
       " 'many',\n",
       " 'design',\n",
       " 'looking',\n",
       " 'weeks',\n",
       " 'say',\n",
       " 'wanted',\n",
       " 'look',\n",
       " 'place',\n",
       " 'purchase',\n",
       " 'looks',\n",
       " 'second',\n",
       " 'piece',\n",
       " 'box',\n",
       " 'pretty',\n",
       " 'trying',\n",
       " 'difficult',\n",
       " 'together',\n",
       " 'though',\n",
       " 'give',\n",
       " 'started',\n",
       " 'anything',\n",
       " 'last',\n",
       " 'company',\n",
       " 'come',\n",
       " 'returned',\n",
       " 'maybe',\n",
       " 'took',\n",
       " 'broke',\n",
       " 'makes',\n",
       " 'stay',\n",
       " 'instead',\n",
       " 'idea',\n",
       " 'head',\n",
       " 'said',\n",
       " 'less',\n",
       " 'went',\n",
       " 'working',\n",
       " 'high',\n",
       " 'unit',\n",
       " 'seems',\n",
       " 'picture',\n",
       " 'completely',\n",
       " 'wish',\n",
       " 'buying',\n",
       " 'babies',\n",
       " 'won',\n",
       " 'tub',\n",
       " 'almost',\n",
       " 'either']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.00850205]),\n",
       " array([0.06654608]),\n",
       " array([0.06589076]),\n",
       " array([0.00501744]),\n",
       " array([-0.05386015]),\n",
       " array([-0.00350488]),\n",
       " array([0.06479459]),\n",
       " array([0.04543563]),\n",
       " array([0.00398353]),\n",
       " array([0.02007754]),\n",
       " array([0.030135]),\n",
       " array([-0.02871155]),\n",
       " array([0.0152162]),\n",
       " array([0.00027259]),\n",
       " array([0.01194482]),\n",
       " array([-0.01824619]),\n",
       " array([-0.01217064]),\n",
       " array([-0.04151103]),\n",
       " array([0.0027682]),\n",
       " array([0.0177032]),\n",
       " array([-0.004397]),\n",
       " array([0.0449764]),\n",
       " array([0.00990916]),\n",
       " array([0.00089924]),\n",
       " array([-0.0013622]),\n",
       " array([0.01268594]),\n",
       " array([0.00826467]),\n",
       " array([-0.0277427]),\n",
       " array([0.00061013]),\n",
       " array([0.01540845]),\n",
       " array([-0.01321348]),\n",
       " array([-0.03005125]),\n",
       " array([0.02973994]),\n",
       " array([0.01840871]),\n",
       " array([0.00286179]),\n",
       " array([-0.0105768]),\n",
       " array([-0.00065735]),\n",
       " array([-0.01014766]),\n",
       " array([-0.0047958]),\n",
       " array([0.00750892]),\n",
       " array([0.00427938]),\n",
       " array([0.00306786]),\n",
       " array([-0.00220318]),\n",
       " array([0.00957273]),\n",
       " array([9.91666827e-05]),\n",
       " array([-0.01984626]),\n",
       " array([0.01757027]),\n",
       " array([0.00155479]),\n",
       " array([-0.01773754]),\n",
       " array([0.00978324]),\n",
       " array([0.01170316]),\n",
       " array([-0.00735346]),\n",
       " array([-0.00608714]),\n",
       " array([0.00643767]),\n",
       " array([0.01071597]),\n",
       " array([-0.00305345]),\n",
       " array([0.00717191]),\n",
       " array([0.0057332]),\n",
       " array([0.00460662]),\n",
       " array([-0.00520588]),\n",
       " array([0.00671012]),\n",
       " array([0.00903282]),\n",
       " array([0.00174563]),\n",
       " array([0.0060028]),\n",
       " array([0.01201817]),\n",
       " array([-0.01835946]),\n",
       " array([-0.00691011]),\n",
       " array([-0.01386873]),\n",
       " array([-0.01504066]),\n",
       " array([0.00592354]),\n",
       " array([0.00567479]),\n",
       " array([-0.00528786]),\n",
       " array([0.00308148]),\n",
       " array([0.00553751]),\n",
       " array([0.01499179]),\n",
       " array([-0.00033567]),\n",
       " array([-0.03306952]),\n",
       " array([-0.00478991]),\n",
       " array([-0.00641369]),\n",
       " array([0.00799939]),\n",
       " array([-0.00086139]),\n",
       " array([0.0168053]),\n",
       " array([0.01325399]),\n",
       " array([0.00172307]),\n",
       " array([0.00298031]),\n",
       " array([0.00858284]),\n",
       " array([0.01170825]),\n",
       " array([0.00280826]),\n",
       " array([0.00218724]),\n",
       " array([0.01688247]),\n",
       " array([-0.00465974]),\n",
       " array([0.00151368]),\n",
       " array([-0.01095091]),\n",
       " array([0.00917843]),\n",
       " array([-0.00018857]),\n",
       " array([-0.03898204]),\n",
       " array([-0.0244821]),\n",
       " array([-0.01870237]),\n",
       " array([-0.02139435]),\n",
       " array([-0.01296905]),\n",
       " array([-0.01713787]),\n",
       " array([-0.01375668]),\n",
       " array([-0.01497704]),\n",
       " array([-0.00510288]),\n",
       " array([-0.02897898]),\n",
       " array([-0.01486632]),\n",
       " array([-0.01280884]),\n",
       " array([-0.01077094]),\n",
       " array([-0.00695287]),\n",
       " array([-0.00504082]),\n",
       " array([-0.00925914]),\n",
       " array([-0.02404275]),\n",
       " array([-0.02659278]),\n",
       " array([-0.00197321]),\n",
       " array([-0.00504128]),\n",
       " array([-0.00700792]),\n",
       " array([-0.00348089]),\n",
       " array([-0.00640959]),\n",
       " array([-0.00407497]),\n",
       " array([-0.00630054]),\n",
       " array([-0.01091879]),\n",
       " array([-0.01260519]),\n",
       " array([-0.00166895]),\n",
       " array([-0.00776419]),\n",
       " array([-0.00051596]),\n",
       " array([-0.001942]),\n",
       " array([-0.00124762]),\n",
       " array([-0.00501292]),\n",
       " array([-0.00912049]),\n",
       " array([-0.00722099]),\n",
       " array([-0.00831783]),\n",
       " array([-0.00560573]),\n",
       " array([-0.01470983]),\n",
       " array([-0.00931521]),\n",
       " array([-0.00222034]),\n",
       " array([-0.00707573]),\n",
       " array([-0.00510116]),\n",
       " array([-0.00893573]),\n",
       " array([-0.01275457]),\n",
       " array([-0.00704172]),\n",
       " array([-0.00097622]),\n",
       " array([0.00041209]),\n",
       " array([0.00082925]),\n",
       " array([0.00264661]),\n",
       " array([-0.00773229]),\n",
       " array([0.00153471]),\n",
       " array([-0.00737263]),\n",
       " array([-0.00373694]),\n",
       " array([-0.00381416]),\n",
       " array([-0.00164575]),\n",
       " array([-0.00331888]),\n",
       " array([0.00122258]),\n",
       " array([1.36699286e-05]),\n",
       " array([-0.00301867]),\n",
       " array([-0.01028263]),\n",
       " array([-0.01066913]),\n",
       " array([0.00223639]),\n",
       " array([-0.00987425]),\n",
       " array([-0.0102192]),\n",
       " array([-0.00341331]),\n",
       " array([0.0033449]),\n",
       " array([-0.00350985]),\n",
       " array([-0.00626283]),\n",
       " array([-0.0072242]),\n",
       " array([-0.00547016]),\n",
       " array([-0.01250639]),\n",
       " array([-0.00247806]),\n",
       " array([-0.0160018]),\n",
       " array([-0.00640099]),\n",
       " array([-0.00426644]),\n",
       " array([-0.0155377]),\n",
       " array([0.00231349]),\n",
       " array([-0.00906653]),\n",
       " array([-0.00630013]),\n",
       " array([-0.01210103]),\n",
       " array([-0.00302579]),\n",
       " array([-0.0067629]),\n",
       " array([-0.00565499]),\n",
       " array([-0.0068705]),\n",
       " array([-0.01189506]),\n",
       " array([-0.00018649]),\n",
       " array([-0.01152305]),\n",
       " array([0.00281533]),\n",
       " array([-0.0081015]),\n",
       " array([-0.01000621]),\n",
       " array([0.00402038]),\n",
       " array([-0.005443]),\n",
       " array([0.00285819]),\n",
       " array([0.00011989]),\n",
       " array([-0.00647588]),\n",
       " array([-0.00114494]),\n",
       " array([-0.00709206])]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', array([0.06654608])),\n",
       " ('great', array([0.06589076])),\n",
       " ('like', array([0.06479459])),\n",
       " ('easy', array([0.04543563])),\n",
       " ('much', array([0.0449764])),\n",
       " ('old', array([0.030135])),\n",
       " ('even', array([0.02973994])),\n",
       " ('seat', array([0.02007754])),\n",
       " ('perfect', array([0.01840871])),\n",
       " ('good', array([0.0177032]))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('money', array([-0.0244821])),\n",
       " ('waste', array([-0.02659278])),\n",
       " ('still', array([-0.0277427])),\n",
       " ('well', array([-0.02871155])),\n",
       " ('however', array([-0.02897898])),\n",
       " ('first', array([-0.03005125])),\n",
       " ('bottles', array([-0.03306952])),\n",
       " ('day', array([-0.03898204])),\n",
       " ('bought', array([-0.04151103])),\n",
       " ('use', array([-0.05386015]))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficient_ = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficient_)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True) ## sorting is done based on key \n",
    "word_coefficient_tuples[-10:]\n",
    "\n",
    "display(word_coefficient_tuples[:10])\n",
    "display(word_coefficient_tuples[-10:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
