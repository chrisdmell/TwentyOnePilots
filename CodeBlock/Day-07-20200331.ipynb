{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. speed and performance\n",
    "2. core parallelization\n",
    "3. outperforms single algorithm methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrun data shape -  (14999, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>number_of_projects</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>churn</th>\n",
       "      <th>promotion</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction  evaluation  number_of_projects  average_montly_hours  \\\n",
       "0          0.38        0.53                   2                   157   \n",
       "1          0.80        0.86                   5                   262   \n",
       "2          0.11        0.88                   7                   272   \n",
       "3          0.72        0.87                   5                   223   \n",
       "4          0.37        0.52                   2                   159   \n",
       "\n",
       "   time_spend_company  work_accident  churn  promotion department  salary  \n",
       "0                   3              0      1          0      sales     low  \n",
       "1                   6              0      1          0      sales  medium  \n",
       "2                   4              0      1          0      sales  medium  \n",
       "3                   5              0      1          0      sales     low  \n",
       "4                   3              0      1          0      sales     low  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "churn_data = pd.read_csv(\"churn_data.csv\")\n",
    "print(\"chrun data shape - \",churn_data.shape)\n",
    "display(churn_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = churn_data[[\"churn\"]]\n",
    "X = churn_data.drop([\"churn\"], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn value counts  - \n",
      " 0    11428\n",
      "1     3571\n",
      "Name: churn, dtype: int64\n",
      "\n",
      "\n",
      "unique of departments -  ['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'\n",
      " 'product_mng' 'marketing' 'RandD']\n",
      "\n",
      "\n",
      "unique of departments -  ['low' 'medium' 'high']\n",
      "\n",
      "\n",
      "dtypes of churn data - \n",
      " satisfaction            float64\n",
      "evaluation              float64\n",
      "number_of_projects        int64\n",
      "average_montly_hours      int64\n",
      "time_spend_company        int64\n",
      "work_accident             int64\n",
      "churn                     int64\n",
      "promotion                 int64\n",
      "department               object\n",
      "salary                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"churn value counts  - \\n\",churn_data.churn.value_counts())\n",
    "\n",
    "print(\"\\n\\nunique of departments - \",churn_data.department.unique())\n",
    "\n",
    "print(\"\\n\\nunique of departments - \",churn_data.salary.unique())\n",
    "\n",
    "print(\"\\n\\ndtypes of churn data - \\n\", churn_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgbBoost needs [encoding](http://appliedpredictivemodeling.com/blog/2013/10/23/the-basics-of-encoding-categorical-data-for-predictive-models). xgboost only deals with numeric columns. Using __LIGHTLBM__ or __CATBOOST__ ```categorical_features``` column takes all the categorical variables<br>\n",
    "[```pandas.get_dummies()```](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "categorical_variables = []\n",
    "## convert categorical variables into one hot encoding \n",
    "for col , dtype in zip(X.columns, X.dtypes):\n",
    "    if dtype == object :\n",
    "        categorical_variables.append(col)\n",
    "        ## append s list of categorical variables\n",
    "        \n",
    "for columns in categorical_variables:\n",
    "    ## get dummies\n",
    "    cat_var_dummies = pd.get_dummies(X[columns], prefix= columns, dummy_na=True)\n",
    "    \n",
    "    ## get_dummies ignore Nan rows while getting dummes\n",
    "    \n",
    "    print(X[columns].isna().any())\n",
    "    X.drop([columns], axis = 1 , inplace = True)\n",
    "    \n",
    "    for cols in cat_var_dummies.columns:\n",
    "        X[cols] = cat_var_dummies[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- XG boost check the variables and see for categorical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>number_of_projects</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>promotion</th>\n",
       "      <th>department_IT</th>\n",
       "      <th>department_RandD</th>\n",
       "      <th>department_accounting</th>\n",
       "      <th>...</th>\n",
       "      <th>department_marketing</th>\n",
       "      <th>department_product_mng</th>\n",
       "      <th>department_sales</th>\n",
       "      <th>department_support</th>\n",
       "      <th>department_technical</th>\n",
       "      <th>department_nan</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "      <th>salary_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction  evaluation  number_of_projects  average_montly_hours  \\\n",
       "0          0.38        0.53                   2                   157   \n",
       "\n",
       "   time_spend_company  work_accident  promotion  department_IT  \\\n",
       "0                   3              0          0              0   \n",
       "\n",
       "   department_RandD  department_accounting  ...  department_marketing  \\\n",
       "0                 0                      0  ...                     0   \n",
       "\n",
       "   department_product_mng  department_sales  department_support  \\\n",
       "0                       0                 1                   0   \n",
       "\n",
       "   department_technical  department_nan  salary_high  salary_low  \\\n",
       "0                     0               0            0           1   \n",
       "\n",
       "   salary_medium  salary_nan  \n",
       "0              0           0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[n_estimators for scikit learn API or num_boost_round](https://stackoverflow.com/questions/46234806/what-n-estimators-and-max-features-means-in-randomforestregressor/46234913) [[1]](https://stackoverflow.com/questions/48051749/what-is-the-difference-between-num-boost-round-and-n-estimators)<br>\n",
    "[max_features](https://stackoverflow.com/questions/23939750/understanding-max-features-parameter-in-randomforestregressor/23950648#23950648)<br>\n",
    "[objective and feval in XGB](https://stackoverflow.com/questions/34178287/difference-between-objective-and-feval-in-xgboost)<br>\n",
    "[weight of evidence and information value](https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html)<br>\n",
    "[gamma](https://www.kaggle.com/c/santander-customer-satisfaction/discussion/20662)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:42] ======== Monitor: Learner ========\n",
      "[00:12:42] GetGradient: 0.0156225s, 10 calls @ 1562us\n",
      "[00:12:42] PredictRaw: 0.0024187s, 10 calls @ 241us\n",
      "[00:12:42] UpdateOneIter: 0.197145s, 10 calls @ 19714us\n",
      "[00:12:42] ======== Monitor: GBTree ========\n",
      "[00:12:42] BoostNewTrees: 0.179103s, 10 calls @ 17910us\n",
      "[00:12:42] CommitModel: 0s, 10 calls @ 0us\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris.aloysious\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris.aloysious\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:12:42] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 40, test_size = 0.2)\n",
    "\n",
    "xg_cl = xgb.XGBClassifier(objective = \"binary:logistic\",\n",
    "                          n_estimators = 10,\n",
    "                          seed = 123,\n",
    "                          verbosity = 3)\n",
    "xg_cl.fit (X_train, y_train )\n",
    "\n",
    "pred = xg_cl.predict(X_test)\n",
    "\n",
    "accuracy = float(np.sum(pred==y_test.churn.to_numpy()))/y_test.shape[0]\n",
    "display(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Feature Importance](https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/) using xgbClassifer. <br>\n",
    "Learning Rate and # of trees needs to managed according, if high learning rate, then trees need to be more else vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=10, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=123,\n",
       "              silent=None, subsample=1, verbosity=3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43546143, 0.13948922, 0.16830975, 0.05355989, 0.20317967,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cl.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "xgb.plot_importance(xg_cl, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the classifier: dt_clf_4\n",
    "dt_clf_4 = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "dt_clf_4.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred_4\n",
    "y_pred_4 = dt_clf_4.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the predictions: accuracy\n",
    "## accuracy metric \n",
    "## y_test.churn.to_numpy() makes an array as in  -- array[()]\n",
    "accuracy = float(np.sum(y_pred_4==y_test.churn.to_numpy()))/y_test.shape[0]\n",
    "print(\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2291\n",
      "           1       0.94      0.92      0.93       709\n",
      "\n",
      "    accuracy                           0.97      3000\n",
      "   macro avg       0.96      0.95      0.96      3000\n",
      "weighted avg       0.97      0.97      0.97      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, dt_clf_4.predict(X_test))) #  target_names=target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
      "0          0.030580         0.000403         0.033069        0.001321\n",
      "1          0.026535         0.001432         0.028668        0.000609\n",
      "2          0.027935         0.002434         0.028935        0.002887\n",
      "3          0.025935         0.000317         0.026935        0.000964\n",
      "4          0.027224         0.001442         0.028402        0.000717\n",
      "5          0.026380         0.000667         0.027668        0.000479\n",
      "6          0.026402         0.000778         0.027535        0.000513\n",
      "7          0.026602         0.000889         0.027202        0.000599\n",
      "8          0.025312         0.000758         0.026469        0.000952\n",
      "9          0.025335         0.000793         0.026402        0.000964\n",
      "0.973598\n"
     ]
    }
   ],
   "source": [
    "## xgboost package matrix - it works best on sparse matrix. \n",
    "\n",
    "churn_dmatrix = xgb.DMatrix( data  = X , \n",
    "                             label = y)\n",
    "\n",
    "params = {\"objective\":\"binary:logistic\", \"max_depth\":4}\n",
    "\n",
    "cv_results = xgb.cv(dtrain = churn_dmatrix, \n",
    "                   params = params,  ## params dictionary\n",
    "                   nfold = 4, ## cross validation metric \n",
    "                   num_boost_round = 10, ## trees to build\n",
    "                   metrics = \"error\", ## evaluation metrics\n",
    "                   as_pandas = True )\n",
    "\n",
    "print(cv_results)\n",
    "\n",
    "# Print the accuracy\n",
    "print(((1-cv_results[\"test-error-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- when to use xgboost?\n",
    "-- large # of dataset \n",
    "-- # feature < # sample \n",
    "-- categorical or numerical features or just numerical features. \n",
    "\n",
    "-- when not to use ? \n",
    "-- image recognition/computer vision/ nlp\n",
    "-- # feature > # sample \n",
    "-- xyz \n",
    "\n",
    "-- question \n",
    "XGBoost is a powerful library that scales very well to many samples and works for a variety of supervised learning problems. That said, as Sergey described in the video, you shouldn't always pick it as your default machine learning library when starting a new project, since there are some situations in which it is not the best option. In this exercise, your job is to consider the below examples and select the one which would be the best use of XGBoost.\n",
    "-- xyz predicting clicks and buys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the accuracy metrics\n",
    "\n",
    "-- confusion matrix \n",
    "n*n matric where n is the class to be predicted. ACCURACY/ERROR/SENSITIVITY/SPECIFICITY/\n",
    "sensitivity or recall here will have to focus on one problem either sensitivity or specificity\n",
    "recall - of pos / all pos \n",
    "precision or pos/ all model predicted positive \n",
    "here it is case sensitive \n",
    "specificity proportion of negative values corretly identified. \n",
    "f1 score is the harmonic mean of recall and precision 2(p.r)/(p+r) Why F1 is HM and not AM(arithmatic mean) because HM punishes extreme values, say p = 0 and r = 1 then HM = 0, when precision is 0 meaning the model is useless. \n",
    "\n",
    "ROC = sensitivity vs (1-specificity) (1-specificity) is called false positive rate\n",
    "\n",
    "Will need examples here - like where which metric is needed, which case is it ?\n",
    "\n",
    "Log Loss - AUC ROC it does not take into account the model’s capability to predict higher probability for samples more likely to be positive. meaning probability positive can be 51 or 78 so log loss takes this difference into consideration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|parameter|Gradient boost|[XG boost](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)|\n",
    "|---|---|---|\n",
    "|Parameter estimation|The gradient is used to minimize the loss function (error - difference between the actual values and predicted values). It is basically the partial derivative of the loss function, so it describes the steepness of our error function. |XGBoost stands for Extreme Gradient Boosting. XGBoost is a specific implementation of the Gradient Boosting method which delivers more accurate approximations by using the strengths of second order derivative of the loss function, L1 and L2 regularization and parallel computing.|\n",
    "|Algorithm|In each round of training, the weak learner is built and its predicted values are compared to the actual values. The distance or difference between the prediction and reality represents the error rate of our model.|XGBoost computes second-order gradients, i.e. second partial derivatives of the loss function, which provides more information about the direction of gradients and how to get to the minimum of our loss function.|\n",
    "|missing values|no|yes|\n",
    "|regularization|no|xgboost used a more regularized model formalization to control over-fitting, which gives it better performance.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|parameter|Adaboost|Gradient boost|\n",
    "|---|---|---|\n",
    "||Adaboost makes a stump and the AOS of the next tree is based on the current tree errors - so the tree next made are taking into consideration the errors of previous trees etc etc till there is perfect fit or that we say ki ok end it| In contrast Gradint boost makes a initial guess, for regression it is the mean value - so the first treee is actually a leaf|\n",
    "|stumps|single not more it is a stump thats all| but GB makes a tree of say 8 to 32 leaves usually|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Speed and performance and can run in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### xgbRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(331,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 56.8048  , 100.20036 , 117.93829 , 117.93829 , 116.96602 ,\n",
       "       115.78438 , 110.49217 ,  56.8048  , 108.52645 ,  88.80094 ,\n",
       "       118.17051 ,  68.532295,  53.892273, 114.68697 ,  65.05115 ,\n",
       "       121.31471 ,  90.100876,  56.8048  ,  60.50561 ,  95.792305,\n",
       "        50.19146 , 151.91193 ,  92.06789 ,  58.895   ,  65.05115 ,\n",
       "       119.36126 , 107.01967 ,  56.8048  ,  88.80094 ,  56.8048  ,\n",
       "       107.01967 ,  88.80094 ,  64.83148 , 129.92712 ,  57.02446 ,\n",
       "        53.323647,  56.8048  ,  53.323647, 111.64564 ,  70.93317 ,\n",
       "        90.100876,  50.19146 ,  56.8048  , 101.33838 , 116.96602 ,\n",
       "        67.23235 ,  56.8048  ,  97.10546 ,  67.23235 , 146.41388 ,\n",
       "       151.00188 , 116.96602 , 151.00188 , 127.390594,  56.8048  ,\n",
       "       156.74522 ,  92.06789 , 100.4243  ,  56.8048  ,  92.50175 ,\n",
       "       101.33838 ,  55.194187, 125.00076 , 131.59715 , 126.37818 ,\n",
       "        56.8048  , 125.686935, 143.31319 ,  95.792305, 120.85364 ,\n",
       "       120.05889 , 105.57465 ,  56.8048  , 121.31471 , 168.08264 ,\n",
       "        56.8048  , 143.55373 ,  56.8048  , 143.31319 ,  95.792305,\n",
       "       102.80923 ,  64.83148 ,  65.05115 ,  64.83148 , 135.51416 ,\n",
       "        67.23235 ,  50.19146 ,  95.792305, 119.59156 , 133.21606 ,\n",
       "       124.129166,  92.06789 ,  65.05115 , 128.36545 ,  90.51009 ,\n",
       "        60.50561 , 120.205795, 116.29586 , 100.25427 , 115.78438 ,\n",
       "       130.80658 , 128.28183 , 116.96602 ,  64.83148 , 164.41853 ,\n",
       "        56.8048  , 143.55576 , 146.41388 , 133.21606 , 112.729744,\n",
       "       168.08264 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "x_train,x_test,  y_train , y_test = train_test_split(X, y, random_state = 40)\n",
    "\n",
    "\n",
    "cgb_cl = xgb.XGBRegressor( n_estimators = 10, seed = 123, objective = 'reg:squarederror')\n",
    "display(x_train.shape)\n",
    "display(y_train.shape)\n",
    "## sklearn classifier get ValueError: bad input shape\n",
    "## shape not matching\n",
    "cgb_cl.fit(x_train, y_train)\n",
    "cgb_cl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error  73.67035726598792\n",
      "mean squared error  8959.978148219954\n",
      "R2 score  -0.35474359607908434\n"
     ]
    }
   ],
   "source": [
    "## regression metric\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "\n",
    "print(\"mean absolute error \",mean_absolute_error(y_test, cgb_cl.predict(x_test)))\n",
    "\n",
    "print(\"mean squared error \",mean_squared_error  (y_test, cgb_cl.predict(x_test)))\n",
    "\n",
    "print(\"R2 score \",                     r2_score (y_test, cgb_cl.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">xgboost used CART Trees, where each leaf is a real value then there is threhold, <br>\n",
    ">boosting is an ensemble meta algorithm that is used to convert weak learners to strong learner<br>\n",
    "> [Multi-colieanrty removed](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py)<br>\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(426,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        45\n",
      "           1       0.98      0.96      0.97        98\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.95      0.96      0.95       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y  = load_breast_cancer(return_X_y = True)\n",
    "\n",
    "x_train,x_test,  y_train , y_test = train_test_split(X, y, random_state = 40)\n",
    "cgb_cl = xgb.XGBClassifier( n_estimators = 10, seed = 123, objective = \"binary:logistic\")\n",
    "display(x_train.shape)\n",
    "display(y_train.shape)\n",
    "## sklearn classifier get ValueError: bad input shape\n",
    "## shape not matching\n",
    "cgb_cl.fit(x_train, y_train)\n",
    "cgb_cl.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, cgb_cl.predict(x_test))) #  target_names=target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When not to use xgboost?\n",
    ">image recognition, computer vision, NLP, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost objective function and base learners\n",
    "\n",
    "loss functions:\n",
    "binary:logistic  - when u want the probability\n",
    "reg:linear - for linear\n",
    "reg:logistic - when u want the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[when using CV for multiclass problem set an extra param ```num_class```](https://stackoverflow.com/questions/40116215/xgboost-sklearn-wrapper-value-0for-parameter-num-class-should-be-greater-equal-t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
